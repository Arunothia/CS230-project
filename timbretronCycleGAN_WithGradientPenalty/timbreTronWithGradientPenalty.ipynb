{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# Imports\n",
    "################################\n",
    "\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import glob\n",
    "import re\n",
    "from multiprocessing import cpu_count\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import random\n",
    "from random import sample\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0, # of CUDA devices = 1\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# configs\n",
    "################################\n",
    "\n",
    "#################\n",
    "# spectrogram\n",
    "#################\n",
    "\n",
    "# Mean of flute = -6.438913345336914\n",
    "# Median of flute = -6.118330955505371\n",
    "# stdDev of flute = 4.377377986907959\n",
    "# Max of flute = 1.8442230224609375\n",
    "# Min of flute = -39.0754280090332\n",
    "\n",
    "# Mean of piano = -6.015857219696045\n",
    "# Median of piano = -5.299488544464111\n",
    "# stdDev of piano = 4.420877456665039\n",
    "# Max of piano = 1.5825170278549194\n",
    "# Min of piano = -40.520179748535156\n",
    "\n",
    "spectrogramStats = {\n",
    "                    'flute': {'mean': -6.438913345336914, 'median': -6.118330955505371, 'stdDev': 4.377377986907959, 'max': 1.8442230224609375, 'min': -39.0754280090332},\n",
    "                    'piano': {'mean': -6.015857219696045, 'median': -5.299488544464111, 'stdDev': 4.420877456665039, 'max': 1.5825170278549194, 'min': -40.520179748535156}\n",
    "                    }\n",
    "\n",
    "# standardizationStyleOptions = normal, logNormal, uniform\n",
    "# following needs to be 'SUBTRACTED' from the data\n",
    "centerOffset = {\n",
    "                'flute': {'normal': spectrogramStats['flute']['mean'], 'logNormal': spectrogramStats['flute']['mean'], 'uniform': (spectrogramStats['flute']['min'] + spectrogramStats['flute']['max'])/2},\n",
    "                'piano': {'normal': spectrogramStats['piano']['mean'], 'logNormal': spectrogramStats['piano']['mean'], 'uniform': (spectrogramStats['piano']['min'] + spectrogramStats['piano']['max'])/2}\n",
    "                }\n",
    "\n",
    "# following needs to be 'DIVIDED' to the data\n",
    "divFactor = {\n",
    "            'flute': {'normal': 3*spectrogramStats['flute']['stdDev'], 'logNormal': (1.1*spectrogramStats['flute']['max'] - spectrogramStats['flute']['mean']) , 'uniform': 1*(spectrogramStats['flute']['max'] - spectrogramStats['flute']['min'])/2},\n",
    "            'piano': {'normal': 3*spectrogramStats['piano']['stdDev'], 'logNormal': (1.1*spectrogramStats['piano']['max'] - spectrogramStats['piano']['mean']) , 'uniform': 1*(spectrogramStats['piano']['max'] - spectrogramStats['piano']['min'])/2}\n",
    "            }\n",
    "\n",
    "\n",
    "####################\n",
    "# training params\n",
    "####################\n",
    "STANDARDIZATION_STYLE = 'uniform'\n",
    "BATCH_SIZE = 1\n",
    "NUM_WORKERS = 1\n",
    "NUM_EPOCHS = 6\n",
    "LEARNING_RATE = 0.0001\n",
    "LAMBDA_CYCLE = 10\n",
    "LAMBDA_IDENTITY = 5\n",
    "GRADIENT_PENALTY = 10\n",
    "ADAM_BETA1 = 0\n",
    "ADAM_BETA2 = 0.9\n",
    "NUM_RESIDUALS = 9\n",
    "\n",
    "####################\n",
    "# checkpoint options\n",
    "####################\n",
    "SAVE_CHECKPOINTS = True\n",
    "\n",
    "####################\n",
    "# find GPU device\n",
    "####################\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (f'Device = {DEVICE}, # of CUDA devices = {torch.cuda.device_count()}')\n",
    "\n",
    "\n",
    "###################\n",
    "# add fileTag\n",
    "###################\n",
    "fileTag = f'lr_{LEARNING_RATE}_cyc_{LAMBDA_CYCLE}_id_{LAMBDA_IDENTITY}_b1_{ADAM_BETA1}_b2_{ADAM_BETA2}_numRes_{NUM_RESIDUALS}_gp_{GRADIENT_PENALTY}_stdStyle_{STANDARDIZATION_STYLE}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (initial): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (model): Sequential(\n",
      "    (0): Block(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
      "        (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "        (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): LeakyReLU(negative_slope=0.2)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "      (1): LeakyReLU(negative_slope=0.2)\n",
      "      (2): Flatten()\n",
      "      (3): Linear(in_features=1200, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# discriminator\n",
    "################################\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size = 4, stride = stride, padding = 1, bias=True, padding_mode=\"reflect\"),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=1, features=[64, 128, 256, 512], numFlatFeatures = 1200):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # output shape = 168 x 128\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, features[0], kernel_size = 4, stride = 2, padding = 1, bias=True, padding_mode=\"reflect\"),            \n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        layers = []   \n",
    "        in_channels = features[0]\n",
    "        \n",
    "        # linear layer will have 20 x 15 features flattened\n",
    "        for feature in features[1:]:\n",
    "            layers.append(Block(in_channels, feature, stride=1 if feature == features[-1] else 2))\n",
    "            in_channels = feature        \n",
    "        \n",
    "        layers.append(nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"), \n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features = numFlatFeatures, out_features = 1)\n",
    "        ))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.initial(x)\n",
    "        return torch.sigmoid(self.model(x))\n",
    "        \n",
    "    \n",
    "def test():\n",
    "    x = torch.randn((5,1,336,256))\n",
    "    model = Discriminator(in_channels=1)\n",
    "    print (model)\n",
    "    preds = model(x)\n",
    "    print(preds.shape)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (initial): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (down_blocks): ModuleList(\n",
      "    (0): EncoderConvBlock(\n",
      "      (encoderConv): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
      "        (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): EncoderConvBlock(\n",
      "      (encoderConv): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), padding_mode=reflect)\n",
      "        (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (residual_blocks): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): ResidualBlock(\n",
      "      (block): Sequential(\n",
      "        (0): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): EncoderConvBlock(\n",
      "          (encoderConv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=reflect)\n",
      "            (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "            (2): Identity()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up_blocks): ModuleList(\n",
      "    (0): DecoderConvBlock(\n",
      "      (decoderConv): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "        (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (3): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): DecoderConvBlock(\n",
      "      (decoderConv): Sequential(\n",
      "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "        (1): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (2): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (3): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (4): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (last): Conv2d(16, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 336, 256])\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# generator\n",
    "################################\n",
    "\n",
    "class EncoderConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_act=True, use_tanh = False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.encoderConv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            (nn.Tanh() if use_tanh else nn.ReLU(inplace=True)) if use_act else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoderConv(x)\n",
    "\n",
    "\n",
    "class DecoderConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_act=True, use_tanh = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        # nearest neighbor upsample + same convolution\n",
    "        self.decoderConv = nn.Sequential(            \n",
    "            nn.Upsample(scale_factor = 2, mode='nearest'),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=0),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            (nn.Tanh() if use_tanh else nn.ReLU(inplace=True)) if use_act else nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoderConv(x)\n",
    "    \n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, use_tanh = False):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            EncoderConvBlock(channels, channels, use_act = True,  use_tanh = use_tanh, kernel_size=3, stride = 1, padding=1),\n",
    "            EncoderConvBlock(channels, channels, use_act = False, use_tanh = use_tanh, kernel_size=3, stride = 1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, img_channels, use_tanh = False, num_features = 64, num_residuals=9):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # same convolution. output channels = 64\n",
    "        self.initial = nn.Sequential(            \n",
    "            nn.Conv2d(img_channels, num_features, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.down_blocks = nn.ModuleList(\n",
    "            [\n",
    "                # output shape = floor((W - F + 2P) / S) + 1 . \n",
    "                # Wout x Hout = 128 x 168, for Win x Hin = 256 x 336, output channels = 128\n",
    "                EncoderConvBlock(num_features, num_features*2, use_act = True, use_tanh = use_tanh, kernel_size=3, stride=2, padding=1),\n",
    "                \n",
    "                # Wout x Hout = 64 x 84, for Win x Hin = 128 x 168, output channels = 256\n",
    "                EncoderConvBlock(num_features*2, num_features*4, use_act = True, use_tanh = use_tanh, kernel_size=3, stride=2, padding=1),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # same convolutions in residual blocks. Shape remains 64 x 86, numChannels = 256\n",
    "        self.residual_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(num_features*4, use_tanh = use_tanh) for _ in range(num_residuals)]\n",
    "        )\n",
    "\n",
    "        self.up_blocks = nn.ModuleList(\n",
    "            [\n",
    "                # Wout x Hout = 128 x 168, numChannels = 128\n",
    "                DecoderConvBlock(num_features*4, num_features*2, use_act = True, use_tanh = use_tanh),\n",
    "                \n",
    "                # Wout x Hout = 256 x 336, numChannels = 64\n",
    "                DecoderConvBlock(num_features*2, num_features, use_act = True, use_tanh = use_tanh)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # same convolution, numChannels = 1\n",
    "        self.last = nn.Conv2d(num_features, img_channels, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # same convolution\n",
    "        x = self.initial(x)\n",
    "        \n",
    "        # down sampling\n",
    "        for layer in self.down_blocks:\n",
    "            x = layer(x)\n",
    "            \n",
    "        # same convolutions\n",
    "        x = self.residual_blocks(x)\n",
    "        \n",
    "        # upsampling\n",
    "        for layer in self.up_blocks:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # same convolution\n",
    "        x = self.last(x)\n",
    "        \n",
    "        return torch.tanh(x)\n",
    "\n",
    "    \n",
    "def test():\n",
    "    x = torch.randn((5,1,336,256))\n",
    "    model = Generator(img_channels=1, num_features = 16, num_residuals=9)\n",
    "    print (model)\n",
    "    gen = model(x)    \n",
    "    print(gen.shape)\n",
    "\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, rootDir):\n",
    "        'Initialization'\n",
    "        self.rootDir = rootDir\n",
    "        self.fileList = os.listdir(rootDir)        \n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.fileList)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        X = np.load(os.path.join(self.rootDir, self.fileList[index]))\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# dataset class\n",
    "##########################\n",
    "\n",
    "class PianoFluteDataset(Dataset):\n",
    "    def __init__(self, root_piano, root_flute, standardizationStyle):\n",
    "        self.root_piano = root_piano\n",
    "        self.root_flute = root_flute\n",
    "\n",
    "        random.seed(2)\n",
    "        self.piano_images = os.listdir(root_piano)\n",
    "        self.flute_images = sample(os.listdir(root_flute), len(os.listdir(root_flute)))\n",
    "        \n",
    "        self.length_dataset = max(len(self.piano_images), len(self.flute_images))\n",
    "\n",
    "        self.piano_dataset_length = len(self.piano_images)\n",
    "        self.flute_dataset_length = len(self.flute_images)\n",
    "        \n",
    "        self.standardizationStyle = standardizationStyle\n",
    "        \n",
    "        # default to normal for standardizing the data\n",
    "        self.offsetFlute = centerOffset['flute']['normal']\n",
    "        self.offsetPiano = centerOffset['piano']['normal']\n",
    "        \n",
    "        self.divFlute = divFactor['flute']['normal']\n",
    "        self.divPiano = divFactor['piano']['normal']\n",
    "        \n",
    "        if standardizationStyle == 'uniform':\n",
    "            print ('Using uniform assumption...')\n",
    "            self.offsetFlute = centerOffset['flute']['uniform']\n",
    "            self.offsetPiano = centerOffset['piano']['uniform']\n",
    "        \n",
    "            self.divFlute = divFactor['flute']['uniform']\n",
    "            self.divPiano = divFactor['piano']['uniform']\n",
    "            \n",
    "        else:\n",
    "            print ('Using logNormal assumption...')\n",
    "            self.offsetFlute = centerOffset['flute']['logNormal']\n",
    "            self.offsetPiano = centerOffset['piano']['logNormal']\n",
    "        \n",
    "            self.divFlute = divFactor['flute']['logNormal']\n",
    "            self.divPiano = divFactor['piano']['logNormal']\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # samples for training\n",
    "        flute_image = self.flute_images[index % self.flute_dataset_length]\n",
    "        piano_image = self.piano_images[index % self.piano_dataset_length]\n",
    "\n",
    "        flute_path = os.path.join(self.root_flute, flute_image)\n",
    "        piano_path = os.path.join(self.root_piano, piano_image)\n",
    "        \n",
    "        flute_img = np.load(flute_path)\n",
    "        piano_img = np.load(piano_path)\n",
    "        \n",
    "        # add extra dimension for the single channel\n",
    "        flute_img = flute_img[None, :]\n",
    "        piano_img = piano_img[None, :]\n",
    "        \n",
    "        # standardize the scale\n",
    "        flute_img = (flute_img - self.offsetFlute) / self.divFlute\n",
    "        piano_img = (piano_img - self.offsetPiano) / self.divPiano        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # samples for interpolation for gradient penalty purposes\n",
    "        flute_random_sample = self.flute_images[random.randint(0, self.flute_dataset_length - 1)]\n",
    "        piano_random_sample = self.piano_images[random.randint(0, self.piano_dataset_length - 1)]\n",
    "\n",
    "        flute_path = os.path.join(self.root_flute, flute_random_sample)\n",
    "        piano_path = os.path.join(self.root_piano, piano_random_sample)\n",
    "        \n",
    "        flute_rnd = np.load(flute_path)\n",
    "        piano_rnd = np.load(piano_path)\n",
    "        \n",
    "        # add extra dimension for the single channel\n",
    "        flute_rnd = flute_rnd[None, :]\n",
    "        piano_rnd = piano_rnd[None, :]\n",
    "        \n",
    "        # standardize the scale\n",
    "        flute_rnd = (flute_rnd - self.offsetFlute) / self.divFlute\n",
    "        piano_rnd = (piano_rnd - self.offsetPiano) / self.divPiano\n",
    "                        \n",
    "\n",
    "        return flute_img, piano_img, flute_rnd, piano_rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):    \n",
    "    checkpoint = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake, device = 'cpu'):\n",
    "        \n",
    "    b, c, h, w = real.shape\n",
    "    epsilon = torch.rand((b, 1, 1, 1)).repeat(1, c, h, w).to(device)\n",
    "    interpolated_images = real * epsilon + fake * (1 - epsilon)\n",
    "    \n",
    "    mixed_scores = critic(interpolated_images)\n",
    "    gradient = torch.autograd.grad(\n",
    "                    inputs = interpolated_images, \n",
    "                    outputs = mixed_scores,\n",
    "                    grad_outputs = torch.ones_like(mixed_scores),\n",
    "                    create_graph = True,\n",
    "                    retain_graph = True\n",
    "                    )[0]\n",
    "    \n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim = 1)\n",
    "    gradient_penalty = torch.mean((gradient_norm-1)**2)\n",
    "    \n",
    "    \n",
    "    return gradient_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################\n",
    "# paths to directories\n",
    "################################\n",
    "\n",
    "curDir = os.getcwd()\n",
    "trainSetDir = f'{curDir}/../../dataSuperSet/processedData/trainSet'\n",
    "fluteTrainSetDir = f'{trainSetDir}/flute/cqtChunks'\n",
    "pianoTrainSetDir = f'{trainSetDir}/piano/cqtChunks'\n",
    "\n",
    "# create directories to store checkpoint outputs\n",
    "checkPointDir = f'{curDir}/checkPoints'\n",
    "checkPointModelDir = f'{checkPointDir}/models'\n",
    "checkPointImageDir = f'{checkPointDir}/images'\n",
    "checkPointLossTrackingDir = f'{checkPointDir}/lossTracking'\n",
    "\n",
    "os.system(f'mkdir -p {checkPointDir}')\n",
    "os.system(f'mkdir -p {checkPointModelDir}')\n",
    "os.system(f'mkdir -p {checkPointImageDir}')\n",
    "os.system(f'mkdir -p {checkPointLossTrackingDir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using uniform assumption...\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# datasets\n",
    "################################\n",
    "\n",
    "# create dataset\n",
    "dataset = PianoFluteDataset(pianoTrainSetDir, fluteTrainSetDir, STANDARDIZATION_STYLE)\n",
    "\n",
    "# create dataloader\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size = BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# instantiate networks and optimizers\n",
    "#########################################\n",
    "\n",
    "# discriminator piano\n",
    "disc_P = Discriminator(in_channels=1).to(DEVICE)\n",
    "\n",
    "# discriminator flute\n",
    "disc_F = Discriminator(in_channels=1).to(DEVICE)\n",
    "\n",
    "# generator piano\n",
    "gen_P = Generator(img_channels=1, num_residuals = NUM_RESIDUALS).to(DEVICE)\n",
    "\n",
    "# generator piano\n",
    "gen_F = Generator(img_channels=1, num_residuals = NUM_RESIDUALS).to(DEVICE)\n",
    "\n",
    "# optimizer discriminator\n",
    "opt_disc = optim.Adam(list(disc_P.parameters()) + list(disc_F.parameters()), lr = LEARNING_RATE, betas=(ADAM_BETA1, ADAM_BETA2))\n",
    "\n",
    "# optimizer generator\n",
    "opt_gen  = optim.Adam(list(gen_P.parameters())  + list(gen_F.parameters()),  lr = LEARNING_RATE, betas=(ADAM_BETA1, ADAM_BETA2))\n",
    "\n",
    "\n",
    "# Losses\n",
    "\n",
    "# For cycle consistency and identity loss\n",
    "L1 = nn.L1Loss() \n",
    "\n",
    "# adversarial loss\n",
    "mse = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch = 0, idx = 0]:   D_loss = 2.8402328491210938, \t G_loss = 25.530075073242188, \t identity_loss = 1.6447548866271973, \t cycle_loss = 1.6529566049575806\n",
      "[epoch = 0, idx = 400]:   D_loss = 0.6410345435142517, \t G_loss = 1.7861212491989136, \t identity_loss = 0.0739392340183258, \t cycle_loss = 0.07240309566259384\n",
      "[epoch = 0, idx = 800]:   D_loss = 0.6736187934875488, \t G_loss = 1.985235333442688, \t identity_loss = 0.08259585499763489, \t cycle_loss = 0.08477181196212769\n",
      "[epoch = 0, idx = 1200]:   D_loss = 0.5486127138137817, \t G_loss = 1.4438331127166748, \t identity_loss = 0.059190377593040466, \t cycle_loss = 0.06488726288080215\n",
      "[epoch = 0, idx = 1600]:   D_loss = 0.8908679485321045, \t G_loss = 2.642169237136841, \t identity_loss = 0.13734984397888184, \t cycle_loss = 0.13403427600860596\n",
      "[epoch = 0, idx = 2000]:   D_loss = 0.6456790566444397, \t G_loss = 2.8620758056640625, \t identity_loss = 0.13891375064849854, \t cycle_loss = 0.1487942337989807\n",
      "[epoch = 0, idx = 2400]:   D_loss = 0.5093244314193726, \t G_loss = 2.5175323486328125, \t identity_loss = 0.12522950768470764, \t cycle_loss = 0.1270856261253357\n",
      "[epoch = 0, idx = 2800]:   D_loss = 0.7518625259399414, \t G_loss = 1.8260438442230225, \t identity_loss = 0.07843631505966187, \t cycle_loss = 0.08508871495723724\n",
      "[epoch = 0, idx = 3200]:   D_loss = 0.5388997793197632, \t G_loss = 2.0921738147735596, \t identity_loss = 0.08963325619697571, \t cycle_loss = 0.10454749315977097\n",
      "[epoch = 0, idx = 3600]:   D_loss = 0.47466641664505005, \t G_loss = 2.033717155456543, \t identity_loss = 0.08147735893726349, \t cycle_loss = 0.10237057507038116\n",
      "[epoch = 0, idx = 4000]:   D_loss = 0.44730132818222046, \t G_loss = 1.982939600944519, \t identity_loss = 0.07790777087211609, \t cycle_loss = 0.07004841417074203\n",
      "[epoch = 0, idx = 4400]:   D_loss = 0.4991667866706848, \t G_loss = 1.3740695714950562, \t identity_loss = 0.04683026298880577, \t cycle_loss = 0.06267007440328598\n",
      "[epoch = 0, idx = 4800]:   D_loss = 0.4098469316959381, \t G_loss = 1.8468908071517944, \t identity_loss = 0.0516890287399292, \t cycle_loss = 0.0579809844493866\n",
      "[epoch = 0, idx = 5200]:   D_loss = 0.6110793948173523, \t G_loss = 1.5648677349090576, \t identity_loss = 0.07133736461400986, \t cycle_loss = 0.0644238144159317\n",
      "[epoch = 0, idx = 5600]:   D_loss = 0.6052297353744507, \t G_loss = 1.774712324142456, \t identity_loss = 0.08746923506259918, \t cycle_loss = 0.08419673889875412\n",
      "[epoch = 0, idx = 6000]:   D_loss = 0.6152026653289795, \t G_loss = 1.706870675086975, \t identity_loss = 0.05874677002429962, \t cycle_loss = 0.06524963676929474\n",
      "[epoch = 0, idx = 6400]:   D_loss = 0.5407942533493042, \t G_loss = 1.4088375568389893, \t identity_loss = 0.0515047162771225, \t cycle_loss = 0.058011770248413086\n",
      "[epoch = 0, idx = 6800]:   D_loss = 0.6245492696762085, \t G_loss = 1.9643666744232178, \t identity_loss = 0.08404562622308731, \t cycle_loss = 0.08029212057590485\n",
      "[epoch = 0, idx = 7200]:   D_loss = 0.9642384052276611, \t G_loss = 1.9326952695846558, \t identity_loss = 0.06994020193815231, \t cycle_loss = 0.08677035570144653\n",
      "[epoch = 0, idx = 7600]:   D_loss = 0.5706851482391357, \t G_loss = 1.3541045188903809, \t identity_loss = 0.0475650280714035, \t cycle_loss = 0.057991065084934235\n",
      "[epoch = 0, idx = 8000]:   D_loss = 0.9058960676193237, \t G_loss = 1.8170956373214722, \t identity_loss = 0.06844618916511536, \t cycle_loss = 0.06986910104751587\n",
      "[epoch = 0, idx = 8400]:   D_loss = 0.4233666956424713, \t G_loss = 2.340400218963623, \t identity_loss = 0.08622103184461594, \t cycle_loss = 0.11324501037597656\n",
      "[epoch = 0, idx = 8800]:   D_loss = 0.6363394856452942, \t G_loss = 1.5452513694763184, \t identity_loss = 0.055669549852609634, \t cycle_loss = 0.06463078409433365\n",
      "[epoch = 0, idx = 9200]:   D_loss = 0.600614607334137, \t G_loss = 1.3943521976470947, \t identity_loss = 0.07066625356674194, \t cycle_loss = 0.0610186904668808\n",
      "[epoch = 0, idx = 9600]:   D_loss = 0.49187713861465454, \t G_loss = 1.467960238456726, \t identity_loss = 0.044152386486530304, \t cycle_loss = 0.06185778230428696\n",
      "[epoch = 0, idx = 10000]:   D_loss = 0.9292617440223694, \t G_loss = 1.3439078330993652, \t identity_loss = 0.04106961563229561, \t cycle_loss = 0.048632606863975525\n",
      "[epoch = 0, idx = 10400]:   D_loss = 0.5697871446609497, \t G_loss = 2.29571533203125, \t identity_loss = 0.06601596623659134, \t cycle_loss = 0.10180848836898804\n",
      "[epoch = 0, idx = 10800]:   D_loss = 0.8866798877716064, \t G_loss = 1.8788353204727173, \t identity_loss = 0.04004136100411415, \t cycle_loss = 0.05140696465969086\n",
      "[epoch = 0, idx = 11200]:   D_loss = 0.6026751399040222, \t G_loss = 1.3807525634765625, \t identity_loss = 0.05215363949537277, \t cycle_loss = 0.05840149521827698\n",
      "[epoch = 0, idx = 11600]:   D_loss = 0.56296306848526, \t G_loss = 1.3117878437042236, \t identity_loss = 0.03704768419265747, \t cycle_loss = 0.053437426686286926\n",
      "[epoch = 0, idx = 12000]:   D_loss = 0.4343806505203247, \t G_loss = 1.4420864582061768, \t identity_loss = 0.049855612218379974, \t cycle_loss = 0.05932535231113434\n",
      "[epoch = 0, idx = 12400]:   D_loss = 0.6115992069244385, \t G_loss = 1.1864162683486938, \t identity_loss = 0.043735817074775696, \t cycle_loss = 0.053217656910419464\n",
      "[epoch = 0, idx = 12800]:   D_loss = 0.5736754536628723, \t G_loss = 1.7206189632415771, \t identity_loss = 0.06543469429016113, \t cycle_loss = 0.08171823620796204\n",
      "[epoch = 0, idx = 13200]:   D_loss = 0.7496272325515747, \t G_loss = 1.3982021808624268, \t identity_loss = 0.03573788329958916, \t cycle_loss = 0.05321855470538139\n",
      "[epoch = 0, idx = 13600]:   D_loss = 0.4857417345046997, \t G_loss = 1.4572234153747559, \t identity_loss = 0.04973479360342026, \t cycle_loss = 0.050371602177619934\n",
      "[epoch = 0, idx = 14000]:   D_loss = 0.6690018177032471, \t G_loss = 1.5754566192626953, \t identity_loss = 0.04160825163125992, \t cycle_loss = 0.06569183617830276\n",
      "[epoch = 0, idx = 14400]:   D_loss = 0.5425222516059875, \t G_loss = 1.5823894739151, \t identity_loss = 0.044152215123176575, \t cycle_loss = 0.060938358306884766\n",
      "[epoch = 0, idx = 14800]:   D_loss = 0.6706015467643738, \t G_loss = 1.361000418663025, \t identity_loss = 0.03900851681828499, \t cycle_loss = 0.05737495422363281\n",
      "[epoch = 0, idx = 15200]:   D_loss = 0.5265638828277588, \t G_loss = 1.5573915243148804, \t identity_loss = 0.04937632381916046, \t cycle_loss = 0.07053114473819733\n",
      "[epoch = 0, idx = 15600]:   D_loss = 0.5734078884124756, \t G_loss = 1.722844123840332, \t identity_loss = 0.05798906460404396, \t cycle_loss = 0.07718262076377869\n",
      "[epoch = 0, idx = 16000]:   D_loss = 0.6039234399795532, \t G_loss = 1.3990898132324219, \t identity_loss = 0.04747366905212402, \t cycle_loss = 0.048161569982767105\n",
      "[epoch = 0, idx = 16400]:   D_loss = 0.5432549715042114, \t G_loss = 1.6661415100097656, \t identity_loss = 0.057406630367040634, \t cycle_loss = 0.079936683177948\n",
      "[epoch = 0, idx = 16800]:   D_loss = 0.5344934463500977, \t G_loss = 1.5477280616760254, \t identity_loss = 0.050709452480077744, \t cycle_loss = 0.06482719630002975\n",
      "[epoch = 0, idx = 17200]:   D_loss = 0.46566325426101685, \t G_loss = 1.2515869140625, \t identity_loss = 0.03535493463277817, \t cycle_loss = 0.05297023057937622\n",
      "[epoch = 0, idx = 17600]:   D_loss = 0.4977611303329468, \t G_loss = 1.623793363571167, \t identity_loss = 0.0530596598982811, \t cycle_loss = 0.06228000670671463\n",
      "[epoch = 0, idx = 18000]:   D_loss = 0.5275275707244873, \t G_loss = 1.3730826377868652, \t identity_loss = 0.03949333727359772, \t cycle_loss = 0.05476434528827667\n",
      "[epoch = 0, idx = 18400]:   D_loss = 0.5777738690376282, \t G_loss = 1.0771915912628174, \t identity_loss = 0.031116224825382233, \t cycle_loss = 0.04227038472890854\n",
      "[epoch = 0, idx = 18800]:   D_loss = 0.4981187582015991, \t G_loss = 1.4126787185668945, \t identity_loss = 0.04722815752029419, \t cycle_loss = 0.06013272702693939\n",
      "[epoch = 0, idx = 19200]:   D_loss = 0.5280301570892334, \t G_loss = 1.4521081447601318, \t identity_loss = 0.050869449973106384, \t cycle_loss = 0.064363494515419\n",
      "[epoch = 0, idx = 19600]:   D_loss = 0.8795285224914551, \t G_loss = 0.9661445617675781, \t identity_loss = 0.03395247459411621, \t cycle_loss = 0.05008736252784729\n",
      "[epoch = 0, idx = 20000]:   D_loss = 0.6605305671691895, \t G_loss = 1.4027260541915894, \t identity_loss = 0.05301899462938309, \t cycle_loss = 0.055817484855651855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch = 0, idx = 20400]:   D_loss = 3.0122430324554443, \t G_loss = 1.1830214262008667, \t identity_loss = 0.03435884416103363, \t cycle_loss = 0.054728101938962936\n",
      "[epoch = 0, idx = 20800]:   D_loss = 0.47990378737449646, \t G_loss = 2.0387425422668457, \t identity_loss = 0.09156958013772964, \t cycle_loss = 0.09620672464370728\n",
      "[epoch = 0, idx = 21200]:   D_loss = 0.5619277358055115, \t G_loss = 1.6878292560577393, \t identity_loss = 0.07379311323165894, \t cycle_loss = 0.07644487917423248\n",
      "[epoch = 1, idx = 0]:   D_loss = 0.5741740465164185, \t G_loss = 1.4286435842514038, \t identity_loss = 0.05852019786834717, \t cycle_loss = 0.07386209815740585\n",
      "[epoch = 1, idx = 400]:   D_loss = 0.47207164764404297, \t G_loss = 1.3788553476333618, \t identity_loss = 0.03292930871248245, \t cycle_loss = 0.04753102734684944\n",
      "[epoch = 1, idx = 800]:   D_loss = 0.5028615593910217, \t G_loss = 1.2743276357650757, \t identity_loss = 0.0318266898393631, \t cycle_loss = 0.0537203848361969\n",
      "[epoch = 1, idx = 1200]:   D_loss = 0.5240330696105957, \t G_loss = 1.791388988494873, \t identity_loss = 0.053072489798069, \t cycle_loss = 0.08257222175598145\n",
      "[epoch = 1, idx = 1600]:   D_loss = 1.0579993724822998, \t G_loss = 1.1319849491119385, \t identity_loss = 0.038351379334926605, \t cycle_loss = 0.06133180856704712\n",
      "[epoch = 1, idx = 2000]:   D_loss = 0.5525522232055664, \t G_loss = 1.5005958080291748, \t identity_loss = 0.047159112989902496, \t cycle_loss = 0.07486526668071747\n",
      "[epoch = 1, idx = 2400]:   D_loss = 0.4167062044143677, \t G_loss = 2.1555721759796143, \t identity_loss = 0.08677294850349426, \t cycle_loss = 0.09329748153686523\n",
      "[epoch = 1, idx = 2800]:   D_loss = 5.910670757293701, \t G_loss = 1.3047456741333008, \t identity_loss = 0.06043130159378052, \t cycle_loss = 0.07996079325675964\n",
      "[epoch = 1, idx = 3200]:   D_loss = 0.5028398036956787, \t G_loss = 1.7297680377960205, \t identity_loss = 0.05776263028383255, \t cycle_loss = 0.08372404426336288\n",
      "[epoch = 1, idx = 3600]:   D_loss = 0.6748667359352112, \t G_loss = 1.09061598777771, \t identity_loss = 0.033504679799079895, \t cycle_loss = 0.04572603479027748\n",
      "[epoch = 1, idx = 4000]:   D_loss = 0.5263122916221619, \t G_loss = 1.3222187757492065, \t identity_loss = 0.04120220988988876, \t cycle_loss = 0.05793856456875801\n",
      "[epoch = 1, idx = 4400]:   D_loss = 0.5130950212478638, \t G_loss = 1.2649186849594116, \t identity_loss = 0.03598447144031525, \t cycle_loss = 0.04873625934123993\n",
      "[epoch = 1, idx = 4800]:   D_loss = 0.45463401079177856, \t G_loss = 1.4917798042297363, \t identity_loss = 0.04119236022233963, \t cycle_loss = 0.05303177982568741\n",
      "[epoch = 1, idx = 5200]:   D_loss = 0.6006085872650146, \t G_loss = 1.24481201171875, \t identity_loss = 0.03966755419969559, \t cycle_loss = 0.057192668318748474\n",
      "[epoch = 1, idx = 5600]:   D_loss = 0.5118875503540039, \t G_loss = 1.4605799913406372, \t identity_loss = 0.028873786330223083, \t cycle_loss = 0.0480191707611084\n",
      "[epoch = 1, idx = 6000]:   D_loss = 0.49224984645843506, \t G_loss = 1.3790366649627686, \t identity_loss = 0.03634662926197052, \t cycle_loss = 0.04706231877207756\n",
      "[epoch = 1, idx = 6400]:   D_loss = 0.4978042244911194, \t G_loss = 1.1436049938201904, \t identity_loss = 0.030870359390974045, \t cycle_loss = 0.046309441328048706\n",
      "[epoch = 1, idx = 6800]:   D_loss = 0.663301944732666, \t G_loss = 2.012051820755005, \t identity_loss = 0.06600559502840042, \t cycle_loss = 0.06566691398620605\n",
      "[epoch = 1, idx = 7200]:   D_loss = 0.5527303218841553, \t G_loss = 1.2534892559051514, \t identity_loss = 0.03404795005917549, \t cycle_loss = 0.056783564388751984\n",
      "[epoch = 1, idx = 7600]:   D_loss = 0.47473734617233276, \t G_loss = 1.2940181493759155, \t identity_loss = 0.032725315541028976, \t cycle_loss = 0.04765024781227112\n",
      "[epoch = 1, idx = 8000]:   D_loss = 0.47625118494033813, \t G_loss = 1.387817621231079, \t identity_loss = 0.04200198873877525, \t cycle_loss = 0.048479244112968445\n",
      "[epoch = 1, idx = 8400]:   D_loss = 0.5886118412017822, \t G_loss = 1.3068698644638062, \t identity_loss = 0.049395035952329636, \t cycle_loss = 0.05094192177057266\n",
      "[epoch = 1, idx = 8800]:   D_loss = 0.6968109607696533, \t G_loss = 1.3206876516342163, \t identity_loss = 0.028819989413022995, \t cycle_loss = 0.04896847903728485\n",
      "[epoch = 1, idx = 9200]:   D_loss = 0.44790565967559814, \t G_loss = 1.3220188617706299, \t identity_loss = 0.02777894213795662, \t cycle_loss = 0.03904929384589195\n",
      "[epoch = 1, idx = 9600]:   D_loss = 0.45827507972717285, \t G_loss = 1.3647657632827759, \t identity_loss = 0.03095889464020729, \t cycle_loss = 0.05540264770388603\n",
      "[epoch = 1, idx = 10000]:   D_loss = 0.5245486497879028, \t G_loss = 1.2322075366973877, \t identity_loss = 0.02832932211458683, \t cycle_loss = 0.04586728289723396\n",
      "[epoch = 1, idx = 10400]:   D_loss = 0.5897352695465088, \t G_loss = 1.8499735593795776, \t identity_loss = 0.0591924823820591, \t cycle_loss = 0.06507937610149384\n",
      "[epoch = 1, idx = 10800]:   D_loss = 0.5661914348602295, \t G_loss = 1.371079683303833, \t identity_loss = 0.04971681535243988, \t cycle_loss = 0.06651511043310165\n",
      "[epoch = 1, idx = 11200]:   D_loss = 0.5204014778137207, \t G_loss = 1.5756735801696777, \t identity_loss = 0.051968052983284, \t cycle_loss = 0.06455931067466736\n",
      "[epoch = 1, idx = 11600]:   D_loss = 0.5599443912506104, \t G_loss = 1.0487877130508423, \t identity_loss = 0.033129557967185974, \t cycle_loss = 0.046764060854911804\n",
      "[epoch = 1, idx = 12000]:   D_loss = 0.43860459327697754, \t G_loss = 1.2867432832717896, \t identity_loss = 0.03146865963935852, \t cycle_loss = 0.04712953045964241\n",
      "[epoch = 1, idx = 12400]:   D_loss = 0.6541104316711426, \t G_loss = 1.3288156986236572, \t identity_loss = 0.032797761261463165, \t cycle_loss = 0.047858309000730515\n",
      "[epoch = 1, idx = 12800]:   D_loss = 0.4766983389854431, \t G_loss = 1.6697227954864502, \t identity_loss = 0.05892176181077957, \t cycle_loss = 0.06096253544092178\n",
      "[epoch = 1, idx = 13200]:   D_loss = 0.4564611315727234, \t G_loss = 1.5437320470809937, \t identity_loss = 0.04623483121395111, \t cycle_loss = 0.059751030057668686\n",
      "[epoch = 1, idx = 13600]:   D_loss = 0.506196141242981, \t G_loss = 1.2612076997756958, \t identity_loss = 0.0332796648144722, \t cycle_loss = 0.04375839978456497\n",
      "[epoch = 1, idx = 14000]:   D_loss = 0.5758981108665466, \t G_loss = 1.0367662906646729, \t identity_loss = 0.025036748498678207, \t cycle_loss = 0.03821244090795517\n",
      "[epoch = 1, idx = 14400]:   D_loss = 0.750089168548584, \t G_loss = 1.6919249296188354, \t identity_loss = 0.09527558833360672, \t cycle_loss = 0.09025552868843079\n",
      "[epoch = 1, idx = 14800]:   D_loss = 0.4474411606788635, \t G_loss = 1.228495717048645, \t identity_loss = 0.037852317094802856, \t cycle_loss = 0.04468291252851486\n",
      "[epoch = 1, idx = 15200]:   D_loss = 0.5056353807449341, \t G_loss = 1.0405855178833008, \t identity_loss = 0.022962311282753944, \t cycle_loss = 0.03781949728727341\n",
      "[epoch = 1, idx = 15600]:   D_loss = 0.5121053457260132, \t G_loss = 1.422113299369812, \t identity_loss = 0.042235977947711945, \t cycle_loss = 0.058675408363342285\n",
      "[epoch = 1, idx = 16000]:   D_loss = 0.5146587491035461, \t G_loss = 1.2145546674728394, \t identity_loss = 0.03785219043493271, \t cycle_loss = 0.047533899545669556\n",
      "[epoch = 1, idx = 16400]:   D_loss = 0.4823497235774994, \t G_loss = 1.6458712816238403, \t identity_loss = 0.06672459095716476, \t cycle_loss = 0.07125754654407501\n",
      "[epoch = 1, idx = 16800]:   D_loss = 0.5202442407608032, \t G_loss = 1.4818246364593506, \t identity_loss = 0.025911524891853333, \t cycle_loss = 0.04289501905441284\n",
      "[epoch = 1, idx = 17200]:   D_loss = 0.5874242186546326, \t G_loss = 1.3516217470169067, \t identity_loss = 0.02624337002635002, \t cycle_loss = 0.061229247599840164\n",
      "[epoch = 1, idx = 17600]:   D_loss = 0.5532536506652832, \t G_loss = 1.2989715337753296, \t identity_loss = 0.03332292288541794, \t cycle_loss = 0.05880226567387581\n",
      "[epoch = 1, idx = 18000]:   D_loss = 1.1306439638137817, \t G_loss = 1.1961352825164795, \t identity_loss = 0.025192217901349068, \t cycle_loss = 0.04730210080742836\n",
      "[epoch = 1, idx = 18400]:   D_loss = 0.5216397047042847, \t G_loss = 1.2175331115722656, \t identity_loss = 0.04148368537425995, \t cycle_loss = 0.03919975459575653\n",
      "[epoch = 1, idx = 18800]:   D_loss = 0.5316696166992188, \t G_loss = 1.341681957244873, \t identity_loss = 0.04119023680686951, \t cycle_loss = 0.056074678897857666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch = 1, idx = 19200]:   D_loss = 0.5147523880004883, \t G_loss = 1.0619556903839111, \t identity_loss = 0.03824692964553833, \t cycle_loss = 0.04679785296320915\n",
      "[epoch = 1, idx = 19600]:   D_loss = 0.480742871761322, \t G_loss = 1.4700697660446167, \t identity_loss = 0.03302440792322159, \t cycle_loss = 0.06777167320251465\n",
      "[epoch = 1, idx = 20000]:   D_loss = 0.6488030552864075, \t G_loss = 1.2033289670944214, \t identity_loss = 0.03515210002660751, \t cycle_loss = 0.06428214907646179\n",
      "[epoch = 1, idx = 20400]:   D_loss = 0.44490841031074524, \t G_loss = 1.6148523092269897, \t identity_loss = 0.05258115008473396, \t cycle_loss = 0.06463932245969772\n",
      "[epoch = 1, idx = 20800]:   D_loss = 0.4092012941837311, \t G_loss = 2.0143496990203857, \t identity_loss = 0.06740473210811615, \t cycle_loss = 0.0716128796339035\n",
      "[epoch = 1, idx = 21200]:   D_loss = 0.5282436013221741, \t G_loss = 0.9462679624557495, \t identity_loss = 0.022981632500886917, \t cycle_loss = 0.036706067621707916\n",
      "[epoch = 2, idx = 0]:   D_loss = 0.5580830574035645, \t G_loss = 1.4588075876235962, \t identity_loss = 0.0344076082110405, \t cycle_loss = 0.047314152121543884\n",
      "[epoch = 2, idx = 400]:   D_loss = 0.46795350313186646, \t G_loss = 1.3526066541671753, \t identity_loss = 0.02969648689031601, \t cycle_loss = 0.04672684520483017\n",
      "[epoch = 2, idx = 800]:   D_loss = 0.4954388737678528, \t G_loss = 1.267229676246643, \t identity_loss = 0.03361757472157478, \t cycle_loss = 0.04429920017719269\n",
      "[epoch = 2, idx = 1200]:   D_loss = 0.6212960481643677, \t G_loss = 1.2605623006820679, \t identity_loss = 0.040971770882606506, \t cycle_loss = 0.04752005636692047\n",
      "[epoch = 2, idx = 1600]:   D_loss = 0.6056204438209534, \t G_loss = 0.8874932527542114, \t identity_loss = 0.02530011720955372, \t cycle_loss = 0.038731638342142105\n",
      "[epoch = 2, idx = 2000]:   D_loss = 0.459983229637146, \t G_loss = 1.1674644947052002, \t identity_loss = 0.028675705194473267, \t cycle_loss = 0.044501304626464844\n",
      "[epoch = 2, idx = 2400]:   D_loss = 0.49154508113861084, \t G_loss = 1.0731744766235352, \t identity_loss = 0.035466164350509644, \t cycle_loss = 0.0418209508061409\n",
      "[epoch = 2, idx = 2800]:   D_loss = 0.9478170871734619, \t G_loss = 0.8873667120933533, \t identity_loss = 0.026408229023218155, \t cycle_loss = 0.04048004746437073\n",
      "[epoch = 2, idx = 3200]:   D_loss = 0.4662940502166748, \t G_loss = 1.1414586305618286, \t identity_loss = 0.029596472159028053, \t cycle_loss = 0.03488806262612343\n",
      "[epoch = 2, idx = 3600]:   D_loss = 0.5068746209144592, \t G_loss = 1.0677921772003174, \t identity_loss = 0.027704458683729172, \t cycle_loss = 0.03532608598470688\n",
      "[epoch = 2, idx = 4000]:   D_loss = 0.47917357087135315, \t G_loss = 1.1208237409591675, \t identity_loss = 0.040299855172634125, \t cycle_loss = 0.03496941924095154\n",
      "[epoch = 2, idx = 4400]:   D_loss = 0.5504772663116455, \t G_loss = 1.4481830596923828, \t identity_loss = 0.03862345218658447, \t cycle_loss = 0.045662738382816315\n",
      "[epoch = 2, idx = 4800]:   D_loss = 0.39659905433654785, \t G_loss = 1.3960360288619995, \t identity_loss = 0.0414995402097702, \t cycle_loss = 0.05735761299729347\n",
      "[epoch = 2, idx = 5200]:   D_loss = 0.5376909971237183, \t G_loss = 1.1306437253952026, \t identity_loss = 0.025442559272050858, \t cycle_loss = 0.0388219989836216\n",
      "[epoch = 2, idx = 5600]:   D_loss = 0.4190122187137604, \t G_loss = 1.5334197282791138, \t identity_loss = 0.037478283047676086, \t cycle_loss = 0.05971584469079971\n",
      "[epoch = 2, idx = 6000]:   D_loss = 3.2412121295928955, \t G_loss = 1.2939701080322266, \t identity_loss = 0.03793743997812271, \t cycle_loss = 0.040580008178949356\n",
      "[epoch = 2, idx = 6400]:   D_loss = 0.5122820138931274, \t G_loss = 1.2002573013305664, \t identity_loss = 0.038325756788253784, \t cycle_loss = 0.04144870862364769\n",
      "[epoch = 2, idx = 6800]:   D_loss = 0.5704224109649658, \t G_loss = 1.032593011856079, \t identity_loss = 0.019862264394760132, \t cycle_loss = 0.043530963361263275\n",
      "[epoch = 2, idx = 7200]:   D_loss = 0.4376288652420044, \t G_loss = 1.1676050424575806, \t identity_loss = 0.025684364140033722, \t cycle_loss = 0.037118617445230484\n",
      "[epoch = 2, idx = 7600]:   D_loss = 0.538348913192749, \t G_loss = 1.426249384880066, \t identity_loss = 0.0493776872754097, \t cycle_loss = 0.054348140954971313\n",
      "[epoch = 2, idx = 8000]:   D_loss = 0.5376189351081848, \t G_loss = 3.112056016921997, \t identity_loss = 0.06117752939462662, \t cycle_loss = 0.21209220588207245\n",
      "[epoch = 2, idx = 8400]:   D_loss = 0.4755015969276428, \t G_loss = 1.24406898021698, \t identity_loss = 0.02656695805490017, \t cycle_loss = 0.04170107841491699\n",
      "[epoch = 2, idx = 8800]:   D_loss = 0.5011551976203918, \t G_loss = 1.4387335777282715, \t identity_loss = 0.029805351048707962, \t cycle_loss = 0.06693263351917267\n",
      "[epoch = 2, idx = 9200]:   D_loss = 0.5196647047996521, \t G_loss = 1.4412775039672852, \t identity_loss = 0.02887692302465439, \t cycle_loss = 0.05615697801113129\n",
      "[epoch = 2, idx = 9600]:   D_loss = 0.46242010593414307, \t G_loss = 1.620558738708496, \t identity_loss = 0.0636177808046341, \t cycle_loss = 0.067962646484375\n",
      "[epoch = 2, idx = 10000]:   D_loss = 0.28944796323776245, \t G_loss = 1.9076776504516602, \t identity_loss = 0.05979585275053978, \t cycle_loss = 0.05861293524503708\n",
      "[epoch = 2, idx = 10400]:   D_loss = 0.6298093199729919, \t G_loss = 1.1363105773925781, \t identity_loss = 0.029145505279302597, \t cycle_loss = 0.04452222213149071\n",
      "[epoch = 2, idx = 10800]:   D_loss = 0.5807322263717651, \t G_loss = 1.1432347297668457, \t identity_loss = 0.027765149250626564, \t cycle_loss = 0.03796805441379547\n",
      "[epoch = 2, idx = 11200]:   D_loss = 0.3824467658996582, \t G_loss = 1.2974979877471924, \t identity_loss = 0.03496185317635536, \t cycle_loss = 0.040746115148067474\n",
      "[epoch = 2, idx = 11600]:   D_loss = 0.5127913355827332, \t G_loss = 1.1325461864471436, \t identity_loss = 0.02089119888842106, \t cycle_loss = 0.034342557191848755\n",
      "[epoch = 2, idx = 12000]:   D_loss = 0.5224816203117371, \t G_loss = 0.9783449172973633, \t identity_loss = 0.023336540907621384, \t cycle_loss = 0.043039605021476746\n",
      "[epoch = 2, idx = 12400]:   D_loss = 0.5505324006080627, \t G_loss = 1.3230693340301514, \t identity_loss = 0.039943233132362366, \t cycle_loss = 0.03932131826877594\n",
      "[epoch = 2, idx = 12800]:   D_loss = 0.461338073015213, \t G_loss = 1.259852409362793, \t identity_loss = 0.036254510283470154, \t cycle_loss = 0.044809531420469284\n",
      "[epoch = 2, idx = 13200]:   D_loss = 0.4627647399902344, \t G_loss = 1.0253868103027344, \t identity_loss = 0.020869793370366096, \t cycle_loss = 0.035257767885923386\n",
      "[epoch = 2, idx = 13600]:   D_loss = 1.123002529144287, \t G_loss = 2.323845386505127, \t identity_loss = 0.10718560963869095, \t cycle_loss = 0.10224498808383942\n",
      "[epoch = 2, idx = 14000]:   D_loss = 0.4664337933063507, \t G_loss = 1.035787582397461, \t identity_loss = 0.021209340542554855, \t cycle_loss = 0.03268168121576309\n",
      "[epoch = 2, idx = 14400]:   D_loss = 0.4398236870765686, \t G_loss = 1.178824543952942, \t identity_loss = 0.029996369034051895, \t cycle_loss = 0.04135848209261894\n",
      "[epoch = 2, idx = 14800]:   D_loss = 0.510287344455719, \t G_loss = 1.1121373176574707, \t identity_loss = 0.022443722933530807, \t cycle_loss = 0.036613062024116516\n",
      "[epoch = 2, idx = 15200]:   D_loss = 0.47652101516723633, \t G_loss = 1.568544864654541, \t identity_loss = 0.0472230538725853, \t cycle_loss = 0.05844138562679291\n",
      "[epoch = 2, idx = 15600]:   D_loss = 0.49011945724487305, \t G_loss = 1.1737301349639893, \t identity_loss = 0.02524752914905548, \t cycle_loss = 0.04426082223653793\n",
      "[epoch = 2, idx = 16000]:   D_loss = 0.4514777958393097, \t G_loss = 1.0609990358352661, \t identity_loss = 0.023408446460962296, \t cycle_loss = 0.03459852561354637\n",
      "[epoch = 2, idx = 16400]:   D_loss = 0.4801443815231323, \t G_loss = 1.495173692703247, \t identity_loss = 0.048009246587753296, \t cycle_loss = 0.05028176307678223\n",
      "[epoch = 2, idx = 16800]:   D_loss = 0.4641742706298828, \t G_loss = 1.1418280601501465, \t identity_loss = 0.026403166353702545, \t cycle_loss = 0.03956222161650658\n",
      "[epoch = 2, idx = 17200]:   D_loss = 1.24811851978302, \t G_loss = 1.2543950080871582, \t identity_loss = 0.027993250638246536, \t cycle_loss = 0.03904955834150314\n",
      "[epoch = 2, idx = 17600]:   D_loss = 0.48236823081970215, \t G_loss = 1.1822749376296997, \t identity_loss = 0.0384841226041317, \t cycle_loss = 0.03874129429459572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch = 2, idx = 18000]:   D_loss = 0.4386780261993408, \t G_loss = 1.2588481903076172, \t identity_loss = 0.036617621779441833, \t cycle_loss = 0.043211646378040314\n",
      "[epoch = 2, idx = 18400]:   D_loss = 1.1335467100143433, \t G_loss = 0.9403289556503296, \t identity_loss = 0.0390763133764267, \t cycle_loss = 0.0418730303645134\n",
      "[epoch = 2, idx = 18800]:   D_loss = 0.42367517948150635, \t G_loss = 1.3240350484848022, \t identity_loss = 0.037197113037109375, \t cycle_loss = 0.05175347998738289\n",
      "[epoch = 2, idx = 19200]:   D_loss = 0.4779144525527954, \t G_loss = 1.4260029792785645, \t identity_loss = 0.03319331258535385, \t cycle_loss = 0.06106434762477875\n",
      "[epoch = 2, idx = 19600]:   D_loss = 0.5003498792648315, \t G_loss = 1.1622941493988037, \t identity_loss = 0.02691233716905117, \t cycle_loss = 0.039613161236047745\n",
      "[epoch = 2, idx = 20000]:   D_loss = 0.5019424557685852, \t G_loss = 1.3271833658218384, \t identity_loss = 0.03158922493457794, \t cycle_loss = 0.04700477421283722\n",
      "[epoch = 2, idx = 20400]:   D_loss = 0.41032975912094116, \t G_loss = 1.2111276388168335, \t identity_loss = 0.023818306624889374, \t cycle_loss = 0.03852191939949989\n",
      "[epoch = 2, idx = 20800]:   D_loss = 0.5093210935592651, \t G_loss = 1.1163771152496338, \t identity_loss = 0.029832353815436363, \t cycle_loss = 0.0417022779583931\n",
      "[epoch = 2, idx = 21200]:   D_loss = 0.5258011817932129, \t G_loss = 1.1940714120864868, \t identity_loss = 0.028954967856407166, \t cycle_loss = 0.039265505969524384\n",
      "[epoch = 3, idx = 0]:   D_loss = 0.4918937087059021, \t G_loss = 1.4948186874389648, \t identity_loss = 0.03928317502140999, \t cycle_loss = 0.05682333558797836\n",
      "[epoch = 3, idx = 400]:   D_loss = 0.5124050378799438, \t G_loss = 1.0161373615264893, \t identity_loss = 0.027940373867750168, \t cycle_loss = 0.0321996733546257\n",
      "[epoch = 3, idx = 800]:   D_loss = 0.5699379444122314, \t G_loss = 1.3065792322158813, \t identity_loss = 0.03018280863761902, \t cycle_loss = 0.045149803161621094\n",
      "[epoch = 3, idx = 1200]:   D_loss = 0.5046488046646118, \t G_loss = 1.1285278797149658, \t identity_loss = 0.02234777808189392, \t cycle_loss = 0.03681506961584091\n",
      "[epoch = 3, idx = 1600]:   D_loss = 0.47097527980804443, \t G_loss = 1.2319096326828003, \t identity_loss = 0.032121703028678894, \t cycle_loss = 0.04081027954816818\n",
      "[epoch = 3, idx = 2000]:   D_loss = 0.4613344967365265, \t G_loss = 1.204682469367981, \t identity_loss = 0.037208765745162964, \t cycle_loss = 0.04306766390800476\n",
      "[epoch = 3, idx = 2400]:   D_loss = 0.4510941505432129, \t G_loss = 1.1652030944824219, \t identity_loss = 0.022711634635925293, \t cycle_loss = 0.03672066703438759\n",
      "[epoch = 3, idx = 2800]:   D_loss = 0.4822763204574585, \t G_loss = 1.211066722869873, \t identity_loss = 0.027426479384303093, \t cycle_loss = 0.05032128840684891\n",
      "[epoch = 3, idx = 3200]:   D_loss = 0.47059282660484314, \t G_loss = 1.2088974714279175, \t identity_loss = 0.02469976246356964, \t cycle_loss = 0.03636442869901657\n",
      "[epoch = 3, idx = 3600]:   D_loss = 0.5945529937744141, \t G_loss = 1.22931969165802, \t identity_loss = 0.03516790643334389, \t cycle_loss = 0.05028264597058296\n",
      "[epoch = 3, idx = 4000]:   D_loss = 0.4032629728317261, \t G_loss = 1.2530890703201294, \t identity_loss = 0.030847549438476562, \t cycle_loss = 0.03750346601009369\n",
      "[epoch = 3, idx = 4400]:   D_loss = 0.525475800037384, \t G_loss = 1.071568489074707, \t identity_loss = 0.0263715460896492, \t cycle_loss = 0.038007501512765884\n",
      "[epoch = 3, idx = 4800]:   D_loss = 0.4813363552093506, \t G_loss = 1.1869817972183228, \t identity_loss = 0.02708044834434986, \t cycle_loss = 0.04039451479911804\n",
      "[epoch = 3, idx = 5200]:   D_loss = 0.9918277263641357, \t G_loss = 1.0019041299819946, \t identity_loss = 0.042535360902547836, \t cycle_loss = 0.05000525712966919\n",
      "[epoch = 3, idx = 5600]:   D_loss = 0.51038658618927, \t G_loss = 1.3525292873382568, \t identity_loss = 0.03694039583206177, \t cycle_loss = 0.04867304861545563\n",
      "[epoch = 3, idx = 6000]:   D_loss = 0.5491209626197815, \t G_loss = 1.5114288330078125, \t identity_loss = 0.03576701879501343, \t cycle_loss = 0.0595364086329937\n",
      "[epoch = 3, idx = 6400]:   D_loss = 0.5313459634780884, \t G_loss = 1.2187409400939941, \t identity_loss = 0.024323470890522003, \t cycle_loss = 0.046652279794216156\n",
      "[epoch = 3, idx = 6800]:   D_loss = 0.49204227328300476, \t G_loss = 1.232773780822754, \t identity_loss = 0.04105796664953232, \t cycle_loss = 0.041014060378074646\n",
      "[epoch = 3, idx = 7200]:   D_loss = 0.5216947197914124, \t G_loss = 1.2708903551101685, \t identity_loss = 0.041057564318180084, \t cycle_loss = 0.0474000945687294\n",
      "[epoch = 3, idx = 7600]:   D_loss = 0.5155691504478455, \t G_loss = 1.1131837368011475, \t identity_loss = 0.0268405694514513, \t cycle_loss = 0.04204008728265762\n",
      "[epoch = 3, idx = 8000]:   D_loss = 0.5337764024734497, \t G_loss = 1.1179640293121338, \t identity_loss = 0.03166407719254494, \t cycle_loss = 0.03657940775156021\n",
      "[epoch = 3, idx = 8400]:   D_loss = 0.5442110896110535, \t G_loss = 1.129018783569336, \t identity_loss = 0.030201241374015808, \t cycle_loss = 0.03972802311182022\n",
      "[epoch = 3, idx = 8800]:   D_loss = 0.4837740957736969, \t G_loss = 1.4793038368225098, \t identity_loss = 0.03756394609808922, \t cycle_loss = 0.05525006353855133\n",
      "[epoch = 3, idx = 9200]:   D_loss = 0.5039712190628052, \t G_loss = 1.183732271194458, \t identity_loss = 0.02328535169363022, \t cycle_loss = 0.045996297150850296\n",
      "[epoch = 3, idx = 9600]:   D_loss = 0.5091540813446045, \t G_loss = 1.2097804546356201, \t identity_loss = 0.030929982662200928, \t cycle_loss = 0.049303557723760605\n",
      "[epoch = 3, idx = 10000]:   D_loss = 0.5393369197845459, \t G_loss = 1.0166916847229004, \t identity_loss = 0.02684597671031952, \t cycle_loss = 0.04589049145579338\n",
      "[epoch = 3, idx = 10400]:   D_loss = 0.4900290369987488, \t G_loss = 0.9239704012870789, \t identity_loss = 0.022988833487033844, \t cycle_loss = 0.029368247836828232\n",
      "[epoch = 3, idx = 10800]:   D_loss = 0.5141152739524841, \t G_loss = 1.0360805988311768, \t identity_loss = 0.019053349271416664, \t cycle_loss = 0.0391855463385582\n",
      "[epoch = 3, idx = 11200]:   D_loss = 0.5461183786392212, \t G_loss = 1.2271543741226196, \t identity_loss = 0.02147209271788597, \t cycle_loss = 0.052379995584487915\n",
      "[epoch = 3, idx = 11600]:   D_loss = 0.5491352677345276, \t G_loss = 0.8870794773101807, \t identity_loss = 0.02071213349699974, \t cycle_loss = 0.03478732705116272\n",
      "[epoch = 3, idx = 12000]:   D_loss = 0.5118334293365479, \t G_loss = 1.0953229665756226, \t identity_loss = 0.019573774188756943, \t cycle_loss = 0.03727630525827408\n",
      "[epoch = 3, idx = 12400]:   D_loss = 0.5573283433914185, \t G_loss = 1.0962556600570679, \t identity_loss = 0.027082104235887527, \t cycle_loss = 0.03757774829864502\n",
      "[epoch = 3, idx = 12800]:   D_loss = 0.565619170665741, \t G_loss = 1.2014281749725342, \t identity_loss = 0.03185968101024628, \t cycle_loss = 0.05437879636883736\n",
      "[epoch = 3, idx = 13200]:   D_loss = 0.5299320816993713, \t G_loss = 1.1828312873840332, \t identity_loss = 0.022806406021118164, \t cycle_loss = 0.041805434972047806\n",
      "[epoch = 3, idx = 13600]:   D_loss = 0.477655827999115, \t G_loss = 1.3668866157531738, \t identity_loss = 0.048574961721897125, \t cycle_loss = 0.04744027554988861\n",
      "[epoch = 3, idx = 14000]:   D_loss = 0.5942226648330688, \t G_loss = 1.1430730819702148, \t identity_loss = 0.023202331736683846, \t cycle_loss = 0.03614148497581482\n",
      "[epoch = 3, idx = 14400]:   D_loss = 1.1008169651031494, \t G_loss = 0.7607306241989136, \t identity_loss = 0.02078207954764366, \t cycle_loss = 0.03588467091321945\n",
      "[epoch = 3, idx = 14800]:   D_loss = 0.4863303303718567, \t G_loss = 1.1190134286880493, \t identity_loss = 0.028885431587696075, \t cycle_loss = 0.035149648785591125\n",
      "[epoch = 3, idx = 15200]:   D_loss = 0.537739634513855, \t G_loss = 1.0964592695236206, \t identity_loss = 0.02023272030055523, \t cycle_loss = 0.033676426857709885\n",
      "[epoch = 3, idx = 15600]:   D_loss = 0.49244424700737, \t G_loss = 1.115537405014038, \t identity_loss = 0.024934913963079453, \t cycle_loss = 0.037586938589811325\n",
      "[epoch = 3, idx = 16000]:   D_loss = 0.4982738792896271, \t G_loss = 1.0745500326156616, \t identity_loss = 0.02141668274998665, \t cycle_loss = 0.034113429486751556\n",
      "[epoch = 3, idx = 16400]:   D_loss = 0.595691442489624, \t G_loss = 1.3652827739715576, \t identity_loss = 0.028056008741259575, \t cycle_loss = 0.04786551371216774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch = 3, idx = 16800]:   D_loss = 0.5156246423721313, \t G_loss = 1.0065664052963257, \t identity_loss = 0.03049841709434986, \t cycle_loss = 0.04091869667172432\n",
      "[epoch = 3, idx = 17200]:   D_loss = 0.5486987233161926, \t G_loss = 1.0411036014556885, \t identity_loss = 0.024800177663564682, \t cycle_loss = 0.03468839079141617\n",
      "[epoch = 3, idx = 17600]:   D_loss = 0.4198361039161682, \t G_loss = 1.0675760507583618, \t identity_loss = 0.016473108902573586, \t cycle_loss = 0.033412497490644455\n",
      "[epoch = 3, idx = 18000]:   D_loss = 0.5852441787719727, \t G_loss = 0.8881850242614746, \t identity_loss = 0.02426673099398613, \t cycle_loss = 0.036345914006233215\n",
      "[epoch = 3, idx = 18400]:   D_loss = 0.43217355012893677, \t G_loss = 1.1548255681991577, \t identity_loss = 0.02115211822092533, \t cycle_loss = 0.04409048706293106\n",
      "[epoch = 3, idx = 18800]:   D_loss = 1.2710583209991455, \t G_loss = 1.0718966722488403, \t identity_loss = 0.026825297623872757, \t cycle_loss = 0.045970283448696136\n",
      "[epoch = 3, idx = 19200]:   D_loss = 0.5064855217933655, \t G_loss = 1.167215347290039, \t identity_loss = 0.028651727363467216, \t cycle_loss = 0.03607996180653572\n",
      "[epoch = 3, idx = 19600]:   D_loss = 0.4624321758747101, \t G_loss = 1.1880351305007935, \t identity_loss = 0.030036356300115585, \t cycle_loss = 0.038225241005420685\n",
      "[epoch = 3, idx = 20000]:   D_loss = 0.4804304838180542, \t G_loss = 1.099045991897583, \t identity_loss = 0.03227310627698898, \t cycle_loss = 0.033372052013874054\n",
      "[epoch = 3, idx = 20400]:   D_loss = 0.6305072903633118, \t G_loss = 1.0700867176055908, \t identity_loss = 0.021571334451436996, \t cycle_loss = 0.032806530594825745\n",
      "[epoch = 3, idx = 20800]:   D_loss = 0.4752410054206848, \t G_loss = 1.1984323263168335, \t identity_loss = 0.017410311847925186, \t cycle_loss = 0.040388576686382294\n",
      "[epoch = 3, idx = 21200]:   D_loss = 0.4732818603515625, \t G_loss = 1.1711342334747314, \t identity_loss = 0.022020447999238968, \t cycle_loss = 0.0386245921254158\n",
      "[epoch = 4, idx = 0]:   D_loss = 0.5925254821777344, \t G_loss = 0.9367097616195679, \t identity_loss = 0.01754913106560707, \t cycle_loss = 0.03436550498008728\n",
      "[epoch = 4, idx = 400]:   D_loss = 0.5216795206069946, \t G_loss = 1.0462884902954102, \t identity_loss = 0.02356027439236641, \t cycle_loss = 0.03804284334182739\n",
      "[epoch = 4, idx = 800]:   D_loss = 0.7062357664108276, \t G_loss = 1.20425283908844, \t identity_loss = 0.02977774664759636, \t cycle_loss = 0.056531235575675964\n",
      "[epoch = 4, idx = 1200]:   D_loss = 0.5208472013473511, \t G_loss = 1.1494823694229126, \t identity_loss = 0.022636719048023224, \t cycle_loss = 0.039382971823215485\n",
      "[epoch = 4, idx = 1600]:   D_loss = 0.5914064049720764, \t G_loss = 0.9602893590927124, \t identity_loss = 0.027515456080436707, \t cycle_loss = 0.030209530144929886\n",
      "[epoch = 4, idx = 2000]:   D_loss = 0.4997628927230835, \t G_loss = 1.0876905918121338, \t identity_loss = 0.02453003078699112, \t cycle_loss = 0.036700040102005005\n",
      "[epoch = 4, idx = 2400]:   D_loss = 0.5603421926498413, \t G_loss = 0.9175151586532593, \t identity_loss = 0.02112152799963951, \t cycle_loss = 0.03543813154101372\n",
      "[epoch = 4, idx = 2800]:   D_loss = 0.6906893253326416, \t G_loss = 1.512611746788025, \t identity_loss = 0.021433351561427116, \t cycle_loss = 0.04078974947333336\n",
      "[epoch = 4, idx = 3200]:   D_loss = 0.5162267088890076, \t G_loss = 0.9935488104820251, \t identity_loss = 0.0196143239736557, \t cycle_loss = 0.030715320259332657\n",
      "[epoch = 4, idx = 3600]:   D_loss = 0.4704363942146301, \t G_loss = 1.2385814189910889, \t identity_loss = 0.033287838101387024, \t cycle_loss = 0.04922068864107132\n",
      "[epoch = 4, idx = 4000]:   D_loss = 0.4956720471382141, \t G_loss = 1.2524770498275757, \t identity_loss = 0.035429734736680984, \t cycle_loss = 0.044917911291122437\n",
      "[epoch = 4, idx = 4400]:   D_loss = 0.5273066163063049, \t G_loss = 1.5108506679534912, \t identity_loss = 0.05404706299304962, \t cycle_loss = 0.056284304708242416\n",
      "[epoch = 4, idx = 4800]:   D_loss = 0.463840514421463, \t G_loss = 1.0905119180679321, \t identity_loss = 0.027869950979948044, \t cycle_loss = 0.03876027464866638\n",
      "[epoch = 4, idx = 5200]:   D_loss = 0.49316877126693726, \t G_loss = 1.0051743984222412, \t identity_loss = 0.019949020817875862, \t cycle_loss = 0.03425336256623268\n",
      "[epoch = 4, idx = 5600]:   D_loss = 0.5612773895263672, \t G_loss = 1.0064113140106201, \t identity_loss = 0.02365008369088173, \t cycle_loss = 0.031046520918607712\n",
      "[epoch = 4, idx = 6000]:   D_loss = 0.5239210724830627, \t G_loss = 1.0382184982299805, \t identity_loss = 0.026598487049341202, \t cycle_loss = 0.03239176422357559\n",
      "[epoch = 4, idx = 6400]:   D_loss = 0.5649768710136414, \t G_loss = 0.8255667686462402, \t identity_loss = 0.026776961982250214, \t cycle_loss = 0.0329514816403389\n",
      "[epoch = 4, idx = 6800]:   D_loss = 0.5287157297134399, \t G_loss = 1.056943416595459, \t identity_loss = 0.02304494008421898, \t cycle_loss = 0.03777612745761871\n",
      "[epoch = 4, idx = 7200]:   D_loss = 0.5598316788673401, \t G_loss = 1.0737974643707275, \t identity_loss = 0.01903405413031578, \t cycle_loss = 0.035122573375701904\n",
      "[epoch = 4, idx = 7600]:   D_loss = 0.5070382952690125, \t G_loss = 1.0510743856430054, \t identity_loss = 0.022862110286951065, \t cycle_loss = 0.029967986047267914\n",
      "[epoch = 4, idx = 8000]:   D_loss = 0.46589481830596924, \t G_loss = 1.1660993099212646, \t identity_loss = 0.025348089635372162, \t cycle_loss = 0.03616108372807503\n",
      "[epoch = 4, idx = 8400]:   D_loss = 0.7047699093818665, \t G_loss = 1.085869550704956, \t identity_loss = 0.019867196679115295, \t cycle_loss = 0.035951949656009674\n",
      "[epoch = 4, idx = 8800]:   D_loss = 0.4706239700317383, \t G_loss = 1.2570397853851318, \t identity_loss = 0.026286594569683075, \t cycle_loss = 0.03647729754447937\n",
      "[epoch = 4, idx = 9200]:   D_loss = 0.43972551822662354, \t G_loss = 1.2920458316802979, \t identity_loss = 0.035071052610874176, \t cycle_loss = 0.039062730967998505\n",
      "[epoch = 4, idx = 9600]:   D_loss = 0.5228785872459412, \t G_loss = 1.1585179567337036, \t identity_loss = 0.023009512573480606, \t cycle_loss = 0.04351358115673065\n",
      "[epoch = 4, idx = 10000]:   D_loss = 0.5417471528053284, \t G_loss = 0.9087674617767334, \t identity_loss = 0.026048805564641953, \t cycle_loss = 0.031904563307762146\n",
      "[epoch = 4, idx = 10400]:   D_loss = 0.6079514026641846, \t G_loss = 1.3223835229873657, \t identity_loss = 0.03605194762349129, \t cycle_loss = 0.04087743163108826\n",
      "[epoch = 4, idx = 10800]:   D_loss = 0.5471974611282349, \t G_loss = 0.7899231314659119, \t identity_loss = 0.01731027290225029, \t cycle_loss = 0.03182988986372948\n",
      "[epoch = 4, idx = 11200]:   D_loss = 0.7439708709716797, \t G_loss = 1.2115306854248047, \t identity_loss = 0.01909557916224003, \t cycle_loss = 0.035584188997745514\n",
      "[epoch = 4, idx = 11600]:   D_loss = 0.7454435229301453, \t G_loss = 1.2154289484024048, \t identity_loss = 0.019534897059202194, \t cycle_loss = 0.042148396372795105\n",
      "[epoch = 4, idx = 12000]:   D_loss = 0.47296398878097534, \t G_loss = 1.0409141778945923, \t identity_loss = 0.02427028678357601, \t cycle_loss = 0.027760084718465805\n",
      "[epoch = 4, idx = 12400]:   D_loss = 0.49076616764068604, \t G_loss = 0.9050107002258301, \t identity_loss = 0.017667120322585106, \t cycle_loss = 0.03099117800593376\n",
      "[epoch = 4, idx = 12800]:   D_loss = 0.5675274133682251, \t G_loss = 1.08458411693573, \t identity_loss = 0.020484115928411484, \t cycle_loss = 0.03273611143231392\n",
      "[epoch = 4, idx = 13200]:   D_loss = 0.4606713056564331, \t G_loss = 1.4826819896697998, \t identity_loss = 0.02025866135954857, \t cycle_loss = 0.038738176226615906\n",
      "[epoch = 4, idx = 13600]:   D_loss = 0.503109872341156, \t G_loss = 1.0233330726623535, \t identity_loss = 0.028808794915676117, \t cycle_loss = 0.03156616538763046\n",
      "[epoch = 4, idx = 14000]:   D_loss = 0.5833681225776672, \t G_loss = 1.1936075687408447, \t identity_loss = 0.01858115941286087, \t cycle_loss = 0.031323354691267014\n",
      "[epoch = 4, idx = 14400]:   D_loss = 0.5433741211891174, \t G_loss = 0.9582992792129517, \t identity_loss = 0.019968170672655106, \t cycle_loss = 0.03496808558702469\n",
      "[epoch = 4, idx = 14800]:   D_loss = 0.6545339226722717, \t G_loss = 0.9332592487335205, \t identity_loss = 0.024695785716176033, \t cycle_loss = 0.029583044350147247\n",
      "[epoch = 4, idx = 15200]:   D_loss = 0.5955295562744141, \t G_loss = 1.017541527748108, \t identity_loss = 0.024839065968990326, \t cycle_loss = 0.035795897245407104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch = 4, idx = 15600]:   D_loss = 0.7677164077758789, \t G_loss = 0.7904571294784546, \t identity_loss = 0.01806989684700966, \t cycle_loss = 0.03907797858119011\n",
      "[epoch = 4, idx = 16000]:   D_loss = 0.4770315885543823, \t G_loss = 1.1308248043060303, \t identity_loss = 0.025812819600105286, \t cycle_loss = 0.03337007761001587\n",
      "[epoch = 4, idx = 16400]:   D_loss = 0.5505826473236084, \t G_loss = 1.02887761592865, \t identity_loss = 0.020786959677934647, \t cycle_loss = 0.03283819556236267\n",
      "[epoch = 4, idx = 16800]:   D_loss = 0.7206847667694092, \t G_loss = 1.144757866859436, \t identity_loss = 0.03079722262918949, \t cycle_loss = 0.04066016525030136\n",
      "[epoch = 4, idx = 17200]:   D_loss = 0.570199728012085, \t G_loss = 0.9183504581451416, \t identity_loss = 0.022929824888706207, \t cycle_loss = 0.030282240360975266\n",
      "[epoch = 4, idx = 17600]:   D_loss = 0.5339784622192383, \t G_loss = 1.2737538814544678, \t identity_loss = 0.0430682897567749, \t cycle_loss = 0.042362526059150696\n",
      "[epoch = 4, idx = 18000]:   D_loss = 0.6896492838859558, \t G_loss = 1.5031039714813232, \t identity_loss = 0.017140015959739685, \t cycle_loss = 0.035583458840847015\n",
      "[epoch = 4, idx = 18400]:   D_loss = 0.48243850469589233, \t G_loss = 1.0914921760559082, \t identity_loss = 0.01973801478743553, \t cycle_loss = 0.038604769855737686\n",
      "[epoch = 4, idx = 18800]:   D_loss = 0.5343650579452515, \t G_loss = 1.072365403175354, \t identity_loss = 0.02183806523680687, \t cycle_loss = 0.0559428408741951\n",
      "[epoch = 4, idx = 19200]:   D_loss = 0.49407005310058594, \t G_loss = 1.0181337594985962, \t identity_loss = 0.021344445645809174, \t cycle_loss = 0.03665953874588013\n",
      "[epoch = 4, idx = 19600]:   D_loss = 0.5284376740455627, \t G_loss = 1.2206100225448608, \t identity_loss = 0.019031472504138947, \t cycle_loss = 0.04259846359491348\n",
      "[epoch = 4, idx = 20000]:   D_loss = 0.4620746970176697, \t G_loss = 1.1683661937713623, \t identity_loss = 0.026501726359128952, \t cycle_loss = 0.04225987195968628\n",
      "[epoch = 4, idx = 20400]:   D_loss = 0.45879894495010376, \t G_loss = 1.0382728576660156, \t identity_loss = 0.018970655277371407, \t cycle_loss = 0.03606841713190079\n",
      "[epoch = 4, idx = 20800]:   D_loss = 0.5420335531234741, \t G_loss = 0.9529980421066284, \t identity_loss = 0.020453277975320816, \t cycle_loss = 0.03585679084062576\n",
      "[epoch = 4, idx = 21200]:   D_loss = 0.5158541202545166, \t G_loss = 0.9644432067871094, \t identity_loss = 0.01789712905883789, \t cycle_loss = 0.030511824414134026\n",
      "[epoch = 5, idx = 0]:   D_loss = 0.4944867491722107, \t G_loss = 1.150578498840332, \t identity_loss = 0.029413361102342606, \t cycle_loss = 0.04534434527158737\n",
      "[epoch = 5, idx = 400]:   D_loss = 0.47957298159599304, \t G_loss = 1.1012566089630127, \t identity_loss = 0.019979994744062424, \t cycle_loss = 0.03587774932384491\n",
      "[epoch = 5, idx = 800]:   D_loss = 0.5227487683296204, \t G_loss = 0.8360611200332642, \t identity_loss = 0.017681855708360672, \t cycle_loss = 0.032067231833934784\n",
      "[epoch = 5, idx = 1200]:   D_loss = 0.5686544179916382, \t G_loss = 1.0592589378356934, \t identity_loss = 0.019890356808900833, \t cycle_loss = 0.03201017156243324\n",
      "[epoch = 5, idx = 1600]:   D_loss = 0.5775583982467651, \t G_loss = 1.1081664562225342, \t identity_loss = 0.031223095953464508, \t cycle_loss = 0.04276119917631149\n",
      "[epoch = 5, idx = 2000]:   D_loss = 0.5118870139122009, \t G_loss = 1.1428003311157227, \t identity_loss = 0.03237944096326828, \t cycle_loss = 0.04195397347211838\n",
      "[epoch = 5, idx = 2400]:   D_loss = 0.5141923427581787, \t G_loss = 1.1791023015975952, \t identity_loss = 0.028264880180358887, \t cycle_loss = 0.04658370465040207\n",
      "[epoch = 5, idx = 2800]:   D_loss = 0.4413478374481201, \t G_loss = 1.2812703847885132, \t identity_loss = 0.025969484820961952, \t cycle_loss = 0.03459526598453522\n",
      "[epoch = 5, idx = 3200]:   D_loss = 0.9148341417312622, \t G_loss = 0.5823355317115784, \t identity_loss = 0.018422938883304596, \t cycle_loss = 0.0372287780046463\n",
      "[epoch = 5, idx = 3600]:   D_loss = 0.4609230160713196, \t G_loss = 0.983021080493927, \t identity_loss = 0.022140948101878166, \t cycle_loss = 0.032532788813114166\n",
      "[epoch = 5, idx = 4000]:   D_loss = 0.4233253598213196, \t G_loss = 1.0616021156311035, \t identity_loss = 0.026250820606946945, \t cycle_loss = 0.03458569198846817\n",
      "[epoch = 5, idx = 4400]:   D_loss = 0.41496604681015015, \t G_loss = 1.1297564506530762, \t identity_loss = 0.027265312150120735, \t cycle_loss = 0.03216513246297836\n",
      "[epoch = 5, idx = 4800]:   D_loss = 0.5657773017883301, \t G_loss = 0.88828444480896, \t identity_loss = 0.015999695286154747, \t cycle_loss = 0.03267081826925278\n",
      "[epoch = 5, idx = 5200]:   D_loss = 0.5386656522750854, \t G_loss = 1.0413622856140137, \t identity_loss = 0.018573112785816193, \t cycle_loss = 0.03331366926431656\n",
      "[epoch = 5, idx = 5600]:   D_loss = 0.5513958930969238, \t G_loss = 1.0735390186309814, \t identity_loss = 0.01928732544183731, \t cycle_loss = 0.0356697142124176\n",
      "[epoch = 5, idx = 6000]:   D_loss = 0.4993267059326172, \t G_loss = 0.9764093160629272, \t identity_loss = 0.021544385701417923, \t cycle_loss = 0.03249809890985489\n",
      "[epoch = 5, idx = 6400]:   D_loss = 0.46513813734054565, \t G_loss = 1.097939372062683, \t identity_loss = 0.01909877359867096, \t cycle_loss = 0.04519917815923691\n",
      "[epoch = 5, idx = 6800]:   D_loss = 0.5646223425865173, \t G_loss = 1.0014493465423584, \t identity_loss = 0.02611757442355156, \t cycle_loss = 0.03475375473499298\n",
      "[epoch = 5, idx = 7200]:   D_loss = 0.5714601874351501, \t G_loss = 1.1151771545410156, \t identity_loss = 0.028773188591003418, \t cycle_loss = 0.03759366273880005\n",
      "[epoch = 5, idx = 7600]:   D_loss = 0.6785107851028442, \t G_loss = 0.7094429731369019, \t identity_loss = 0.01912633143365383, \t cycle_loss = 0.02986074984073639\n",
      "[epoch = 5, idx = 8000]:   D_loss = 0.5332145690917969, \t G_loss = 1.1001698970794678, \t identity_loss = 0.025143183767795563, \t cycle_loss = 0.039446987211704254\n",
      "[epoch = 5, idx = 8400]:   D_loss = 0.4350968897342682, \t G_loss = 1.4453983306884766, \t identity_loss = 0.030182689428329468, \t cycle_loss = 0.03643648326396942\n",
      "[epoch = 5, idx = 8800]:   D_loss = 0.5216174721717834, \t G_loss = 1.0198732614517212, \t identity_loss = 0.01696581207215786, \t cycle_loss = 0.03509483486413956\n",
      "[epoch = 5, idx = 9200]:   D_loss = 0.7763317823410034, \t G_loss = 0.7505924701690674, \t identity_loss = 0.022429805248975754, \t cycle_loss = 0.03467315062880516\n",
      "[epoch = 5, idx = 9600]:   D_loss = 0.5884863138198853, \t G_loss = 1.0832228660583496, \t identity_loss = 0.027805721387267113, \t cycle_loss = 0.04660896956920624\n",
      "[epoch = 5, idx = 10000]:   D_loss = 0.6089379191398621, \t G_loss = 0.9172950983047485, \t identity_loss = 0.02164754644036293, \t cycle_loss = 0.031859271228313446\n",
      "[epoch = 5, idx = 10400]:   D_loss = 0.5299480557441711, \t G_loss = 1.0544103384017944, \t identity_loss = 0.023020632565021515, \t cycle_loss = 0.031262658536434174\n",
      "[epoch = 5, idx = 10800]:   D_loss = 0.5712997913360596, \t G_loss = 1.1927602291107178, \t identity_loss = 0.018089618533849716, \t cycle_loss = 0.03705160319805145\n",
      "[epoch = 5, idx = 11200]:   D_loss = 0.47437649965286255, \t G_loss = 0.9286235570907593, \t identity_loss = 0.017849046736955643, \t cycle_loss = 0.03165549784898758\n",
      "[epoch = 5, idx = 11600]:   D_loss = 1.3913860321044922, \t G_loss = 0.9417297840118408, \t identity_loss = 0.01636170595884323, \t cycle_loss = 0.030774850398302078\n",
      "[epoch = 5, idx = 12000]:   D_loss = 0.5470064878463745, \t G_loss = 0.8649851083755493, \t identity_loss = 0.021119309589266777, \t cycle_loss = 0.033545300364494324\n",
      "[epoch = 5, idx = 12400]:   D_loss = 0.5923362374305725, \t G_loss = 1.0128587484359741, \t identity_loss = 0.017090637236833572, \t cycle_loss = 0.03665824234485626\n",
      "[epoch = 5, idx = 12800]:   D_loss = 0.5771716833114624, \t G_loss = 0.9670183658599854, \t identity_loss = 0.020106464624404907, \t cycle_loss = 0.02919244021177292\n",
      "[epoch = 5, idx = 13200]:   D_loss = 0.7027722001075745, \t G_loss = 0.8681116700172424, \t identity_loss = 0.01984451524913311, \t cycle_loss = 0.03256532549858093\n",
      "[epoch = 5, idx = 13600]:   D_loss = 0.6426684856414795, \t G_loss = 1.087032675743103, \t identity_loss = 0.0246187224984169, \t cycle_loss = 0.03503283113241196\n",
      "[epoch = 5, idx = 14000]:   D_loss = 0.45308417081832886, \t G_loss = 1.1507697105407715, \t identity_loss = 0.020501475781202316, \t cycle_loss = 0.033250950276851654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch = 5, idx = 14400]:   D_loss = 0.3668184280395508, \t G_loss = 1.438385009765625, \t identity_loss = 0.029394330456852913, \t cycle_loss = 0.04238024353981018\n",
      "[epoch = 5, idx = 14800]:   D_loss = 0.6035732626914978, \t G_loss = 1.6428803205490112, \t identity_loss = 0.03534357622265816, \t cycle_loss = 0.04109320044517517\n",
      "[epoch = 5, idx = 15200]:   D_loss = 0.5037583112716675, \t G_loss = 1.0559344291687012, \t identity_loss = 0.022628184407949448, \t cycle_loss = 0.03536828234791756\n",
      "[epoch = 5, idx = 15600]:   D_loss = 0.5397672653198242, \t G_loss = 0.9071933031082153, \t identity_loss = 0.018680769950151443, \t cycle_loss = 0.03093056008219719\n",
      "[epoch = 5, idx = 16000]:   D_loss = 0.5186105370521545, \t G_loss = 0.9297454953193665, \t identity_loss = 0.017529789358377457, \t cycle_loss = 0.034540094435214996\n",
      "[epoch = 5, idx = 16400]:   D_loss = 0.48306503891944885, \t G_loss = 1.188388705253601, \t identity_loss = 0.029064495116472244, \t cycle_loss = 0.04702705517411232\n",
      "[epoch = 5, idx = 16800]:   D_loss = 0.5187512040138245, \t G_loss = 1.1184589862823486, \t identity_loss = 0.021714678034186363, \t cycle_loss = 0.035251058638095856\n",
      "[epoch = 5, idx = 17200]:   D_loss = 0.5581998825073242, \t G_loss = 0.9443621039390564, \t identity_loss = 0.020655974745750427, \t cycle_loss = 0.03079165518283844\n",
      "[epoch = 5, idx = 17600]:   D_loss = 0.5465421676635742, \t G_loss = 1.1034772396087646, \t identity_loss = 0.024572979658842087, \t cycle_loss = 0.039127424359321594\n",
      "[epoch = 5, idx = 18000]:   D_loss = 0.6981843709945679, \t G_loss = 1.5077979564666748, \t identity_loss = 0.018779993057250977, \t cycle_loss = 0.031771473586559296\n",
      "[epoch = 5, idx = 18400]:   D_loss = 0.737332820892334, \t G_loss = 0.7486591339111328, \t identity_loss = 0.02064516395330429, \t cycle_loss = 0.031156685203313828\n",
      "[epoch = 5, idx = 18800]:   D_loss = 0.5243246555328369, \t G_loss = 0.9102410078048706, \t identity_loss = 0.026142291724681854, \t cycle_loss = 0.03697199374437332\n",
      "[epoch = 5, idx = 19200]:   D_loss = 0.55477374792099, \t G_loss = 0.9377614259719849, \t identity_loss = 0.01811850443482399, \t cycle_loss = 0.031802400946617126\n",
      "[epoch = 5, idx = 19600]:   D_loss = 0.48967039585113525, \t G_loss = 1.1019867658615112, \t identity_loss = 0.021969445049762726, \t cycle_loss = 0.03661564737558365\n",
      "[epoch = 5, idx = 20000]:   D_loss = 0.5320309400558472, \t G_loss = 0.9600215554237366, \t identity_loss = 0.017017193138599396, \t cycle_loss = 0.03272513672709465\n",
      "[epoch = 5, idx = 20400]:   D_loss = 0.26032933592796326, \t G_loss = 1.466808557510376, \t identity_loss = 0.0342564582824707, \t cycle_loss = 0.04475328326225281\n",
      "[epoch = 5, idx = 20800]:   D_loss = 0.6170656085014343, \t G_loss = 0.9397156834602356, \t identity_loss = 0.01844904199242592, \t cycle_loss = 0.031997524201869965\n",
      "[epoch = 5, idx = 21200]:   D_loss = 0.4834875166416168, \t G_loss = 1.1519076824188232, \t identity_loss = 0.024882709607481956, \t cycle_loss = 0.04124581813812256\n"
     ]
    }
   ],
   "source": [
    "################################\n",
    "# training\n",
    "################################\n",
    "\n",
    "generatorLossProgression = np.zeros(NUM_EPOCHS)\n",
    "discriminatorLossProgression = np.zeros(NUM_EPOCHS)\n",
    "identityLossProgression = np.zeros(NUM_EPOCHS)\n",
    "cycleLossProgression = np.zeros(NUM_EPOCHS)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):    \n",
    "    \n",
    "    for idx, (flute, piano, flute_rnd, piano_rnd) in enumerate(loader):\n",
    "        \n",
    "        # move data to device\n",
    "        piano = piano.to(DEVICE)\n",
    "        flute = flute.to(DEVICE)\n",
    "        \n",
    "        piano_rnd = piano_rnd.to(DEVICE)\n",
    "        flute_rnd = flute_rnd.to(DEVICE)\n",
    "        \n",
    "        ##############################\n",
    "        # Discriminator training\n",
    "        ##############################                       \n",
    "        \n",
    "        # piano generator output \n",
    "        fake_piano = gen_P (flute)        \n",
    "        \n",
    "        # piano discriminator        \n",
    "        D_P_real = disc_P(piano)\n",
    "        D_P_fake = disc_P(fake_piano)\n",
    "        \n",
    "        # real = 1, fake = 0\n",
    "        D_P_real_loss = mse(D_P_real, torch.ones_like(D_P_real))\n",
    "        D_P_fake_loss = mse(D_P_fake, torch.zeros_like(D_P_real))\n",
    "                          \n",
    "        # gradient penalty                        \n",
    "        gp = gradient_penalty(disc_P, piano_rnd, fake_piano, device = DEVICE)\n",
    "        \n",
    "        # total piano disc loss\n",
    "        Disc_piano_loss = D_P_real_loss + D_P_fake_loss + GRADIENT_PENALTY*gp\n",
    "        \n",
    "        \n",
    "        \n",
    "        # flute generator output\n",
    "        fake_flute = gen_F(piano)\n",
    "        \n",
    "        # flute discriminator\n",
    "        D_F_real = disc_F(flute)\n",
    "        D_F_fake = disc_F(fake_flute)\n",
    "        \n",
    "        # real = 1, fake = 0\n",
    "        D_F_real_loss = mse(D_F_real, torch.ones_like(D_F_real))\n",
    "        D_F_fake_loss = mse(D_F_fake, torch.zeros_like(D_F_real))\n",
    "        \n",
    "        # gradient penalty\n",
    "        gp = gradient_penalty(disc_F, flute_rnd, fake_flute, device = DEVICE)\n",
    "        \n",
    "        # total flute disc loss\n",
    "        Disc_flute_loss = D_F_real_loss + D_F_fake_loss + GRADIENT_PENALTY*gp   \n",
    "        \n",
    "        \n",
    "\n",
    "        # Overall discriminator loss\n",
    "        D_loss = (Disc_flute_loss + Disc_piano_loss)/2\n",
    "\n",
    "        # zero out the gradients\n",
    "        opt_disc.zero_grad()\n",
    "        \n",
    "        # backprop\n",
    "        D_loss.backward(retain_graph = True)\n",
    "        \n",
    "        # update discriminator params\n",
    "        opt_disc.step()        \n",
    "        \n",
    "        ##############################\n",
    "        # Generator training\n",
    "        ##############################\n",
    "        \n",
    "        # Adversarial Loss for both generators\n",
    "        D_P_fake = disc_P(fake_piano)\n",
    "        D_F_fake = disc_F(fake_flute)\n",
    "        \n",
    "        # generator wants fake to be detected real\n",
    "        loss_G_F = mse(D_F_fake, torch.ones_like(D_F_fake))\n",
    "        loss_G_P = mse(D_P_fake, torch.ones_like(D_P_fake))\n",
    "\n",
    "        # Cycle Loss\n",
    "        cycle_piano = gen_P(fake_flute)\n",
    "        cycle_flute = gen_F(fake_piano)\n",
    "        cycle_piano_loss = L1(piano, cycle_piano)\n",
    "        cycle_flute_loss = L1(flute, cycle_flute)\n",
    "        \n",
    "        cycle_loss = cycle_flute_loss + cycle_piano_loss\n",
    "\n",
    "        # Identity Loss\n",
    "        identity_flute = gen_F(flute)\n",
    "        identity_piano = gen_P(piano)\n",
    "        identity_piano_loss = L1(piano, identity_piano)\n",
    "        identity_flute_loss = L1(flute, identity_flute)\n",
    "        \n",
    "        identity_loss = identity_flute_loss + identity_piano_loss\n",
    "\n",
    "        # Overall Generator Loss\n",
    "        G_loss = loss_G_F + loss_G_P + cycle_loss*LAMBDA_CYCLE + identity_loss*LAMBDA_IDENTITY\n",
    "\n",
    "        # zero out the gradients\n",
    "        opt_gen.zero_grad()\n",
    "        \n",
    "        # backprop\n",
    "        G_loss.backward()\n",
    "        \n",
    "        # update generator params\n",
    "        opt_gen.step()\n",
    "        \n",
    "        if idx % 400 == 0:\n",
    "            \n",
    "            # print the current losses\n",
    "            print (f'[epoch = {epoch}, idx = {idx}]:   D_loss = {D_loss.item()}, \\t G_loss = {G_loss.item()}, \\t identity_loss = {identity_loss.item()}, \\t cycle_loss = {cycle_loss.item()}')            \n",
    "            \n",
    "        if idx % 5000 == 0:      \n",
    "            \n",
    "            # save the fake piano and flute np array of a sample            \n",
    "            np.save(f'{checkPointImageDir}/originalPiano__idx_{idx}__{fileTag}.npy', np.squeeze(piano.detach().cpu().numpy()[0,:]))\n",
    "            np.save(f'{checkPointImageDir}/fakeFlute__idx_{idx}__{fileTag}.npy', np.squeeze(fake_flute.detach().cpu().numpy()[0,:]))            \n",
    "            np.save(f'{checkPointImageDir}/originalFlute__idx_{idx}__{fileTag}.npy', np.squeeze(flute.detach().cpu().numpy()[0,:]))\n",
    "            np.save(f'{checkPointImageDir}/fakePiano__idx_{idx}__{fileTag}.npy', np.squeeze(fake_piano.detach().cpu().numpy()[0,:]))\n",
    "        \n",
    "        \n",
    "        # aggregate loss over all batches\n",
    "        discriminatorLossProgression[epoch] += D_loss.item()\n",
    "        generatorLossProgression[epoch] += G_loss.item()\n",
    "        identityLossProgression[epoch] += identity_loss.item()\n",
    "        cycleLossProgression[epoch] += cycle_loss.item()\n",
    "                \n",
    "                \n",
    "    \n",
    "    # average loss over the length of dataset\n",
    "    discriminatorLossProgression[epoch] = discriminatorLossProgression[epoch] / len(dataset)\n",
    "    generatorLossProgression[epoch] = generatorLossProgression[epoch] / len(dataset)\n",
    "    identityLossProgression[epoch] = identityLossProgression[epoch] / len(dataset)\n",
    "    cycleLossProgression[epoch] = cycleLossProgression[epoch] / len(dataset)\n",
    "    \n",
    "    # save the model and current losses\n",
    "    if SAVE_CHECKPOINTS:\n",
    "        save_checkpoint(gen_P, opt_gen, filename = f'{checkPointModelDir}/genp__{fileTag}.pth.tar')\n",
    "        save_checkpoint(gen_F, opt_gen, filename = f'{checkPointModelDir}/genf__{fileTag}.pth.tar')\n",
    "        save_checkpoint(disc_P, opt_disc, filename = f'{checkPointModelDir}/criticp__{fileTag}.pth.tar')\n",
    "        save_checkpoint(disc_F, opt_disc, filename = f'{checkPointModelDir}/criticf__{fileTag}.pth.tar')\n",
    "    \n",
    "        # save the lossProgressions\n",
    "        np.save(f'{checkPointLossTrackingDir}/discriminatorLossProgression__{fileTag}.npy', discriminatorLossProgression)\n",
    "        np.save(f'{checkPointLossTrackingDir}/generatorLossProgression__{fileTag}.npy', generatorLossProgression)\n",
    "        np.save(f'{checkPointLossTrackingDir}/identityLossProgression__{fileTag}.npy', identityLossProgression)\n",
    "        np.save(f'{checkPointLossTrackingDir}/cycleLossProgression__{fileTag}.npy', cycleLossProgression)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
